{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00170b4",
   "metadata": {},
   "source": [
    "# XML Feature Extraction - 2D and 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450041a",
   "metadata": {},
   "source": [
    "#### Note: run inside an environment with numpy==1.20.3 e pylidc==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d277ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import six\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from skimage.measure import find_contours\n",
    "from skimage import io\n",
    "import pydicom\n",
    "import pylidc as pl\n",
    "from pylidc.utils import consensus\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc426b37",
   "metadata": {},
   "source": [
    "#### std_limit = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db79d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIDC-IDRI-0001\n",
      "Nodule ID 1\n",
      "LIDC-IDRI-0002\n",
      "Nodule ID 2\n",
      "LIDC-IDRI-0003\n",
      "Loading dicom files ... This may take a moment.\n",
      "Nodule ID 4\n",
      "Nodule ID 5\n",
      "Nodule ID 6\n",
      "LIDC-IDRI-0004\n",
      "Nodule ID 7\n",
      "LIDC-IDRI-0005\n",
      "Nodule ID 8\n",
      "Nodule ID 9\n",
      "Loading dicom files ... This may take a moment.\n",
      "LIDC-IDRI-0006\n",
      "Loading dicom files ... This may take a moment.\n",
      "Nodule ID 12\n",
      "Loading dicom files ... This may take a moment.\n",
      "Nodule ID 14\n",
      "LIDC-IDRI-0007\n",
      "Nodule ID 15\n",
      "Loading dicom files ... This may take a moment.\n",
      "LIDC-IDRI-0008\n",
      "Nodule ID 17\n",
      "Nodule ID 18\n",
      "LIDC-IDRI-0009\n",
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n",
      "LIDC-IDRI-0010\n",
      "Loading dicom files ... This may take a moment.\n",
      "Nodule ID 22\n",
      "Nodule ID 23\n",
      "LIDC-IDRI-0011\n",
      "Nodule ID 24\n",
      "Nodule ID 25\n",
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "33554432 requested and 28833200 written",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1a5d7b732976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mvolume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_volume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexternal_drive_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{nodule_id}_volume.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Aulas/Laboratório de IA e CD/Projeto 1/myenv/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_ctx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    530\u001b[0m                            pickle_kwargs=dict(fix_imports=fix_imports))\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Aulas/Laboratório de IA e CD/Projeto 1/myenv/lib/python3.9/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             for chunk in numpy.nditer(\n",
      "\u001b[0;31mOSError\u001b[0m: 33554432 requested and 28833200 written"
     ]
    }
   ],
   "source": [
    "# Path were the images are stored\n",
    "input_directory = \"/home/cmonteiro/Aulas/Laboratório de IA e CD/Projeto 1/Imagens/LIDC-IDRI\"\n",
    "\n",
    "# Path to the setup file from radiomics\n",
    "params_file = \"/home/cmonteiro/pyradiomics-master/pyradiomics-master/examples/exampleSettings/Params.yaml\"\n",
    "\n",
    "external_drive_path = \"/mnt/d/Projeto 1/std_limit_0.5/\"\n",
    "\n",
    "# Ordered list of all the subfolders\n",
    "patient_folders = sorted(os.listdir(input_directory))\n",
    "nodule_id=0\n",
    "\n",
    "# Dictionary with all the correspondancies\n",
    "nodule_data = {\n",
    "    'Nodule_id': [],\n",
    "    'Patient_id': [],\n",
    "    'Subtlety': [],\n",
    "    'Internalstructure': [],\n",
    "    'Calcification': [],\n",
    "    'Sphericity': [],\n",
    "    'Margin': [],\n",
    "    'Lobulation': [],\n",
    "    'Spiculation': [],\n",
    "    'Texture': [],\n",
    "    'Malignancy': []\n",
    "}\n",
    "\n",
    "malignancy_names = {\n",
    "    1: \"1-Highly Unlikely\",\n",
    "    2: \"2-Moderately Unlikely\",\n",
    "    3: \"3-Indeterminate\",\n",
    "    4: \"4-Moderately Suspicious\",\n",
    "    5: \"5-Highly Suspicious\"\n",
    "}\n",
    "\n",
    "std_limit = 0.5\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    patient_folder_path = os.path.join(input_directory, patient_folder)\n",
    "    \n",
    "    # Id of the patient - 'LIDC-IDRI-xxxx'\n",
    "    patient_id = os.path.basename(patient_folder_path)\n",
    "    print(patient_id)\n",
    "    patient_scans = pl.query(pl.Scan).filter(pl.Scan.patient_id == patient_id, pl.Scan.annotations.any()).all()\n",
    "    \n",
    "    for scan in patient_scans:\n",
    "        nods = scan.cluster_annotations()\n",
    "        \n",
    "        # Iteration for each node\n",
    "        for anns in nods:\n",
    "            nodule_id+=1\n",
    "            \n",
    "            nodule_characteristics = []\n",
    "\n",
    "            # 50% consensus\n",
    "            cmask, cbbox, masks = consensus(anns, clevel=0.5, pad=[(20, 20), (20, 20), (0, 0)])\n",
    "\n",
    "            for i, mask in enumerate(masks):\n",
    "                characteristics = anns[i].feature_vals()\n",
    "                nodule_characteristics.append(characteristics)\n",
    "\n",
    "            # If there was some feature extracted, otherwise the nodule will not be included\n",
    "            if nodule_characteristics:\n",
    "                # Calculation of the stdeviation for each feature\n",
    "                std_deviations = [np.std(characteristic) for characteristic in zip(*nodule_characteristics)]\n",
    "        \n",
    "                # Verify if there is some feature which has a std > std_limit\n",
    "                if any(std > std_limit for std in std_deviations):\n",
    "                    # Ignore this nodule if its std is bigger\n",
    "                    print(f\"Nodule ID {nodule_id}\")\n",
    "\n",
    "                    continue\n",
    "                    \n",
    "                # If the nodule passes the condition: save its cmask and its volume so that it can be used on the extraction \n",
    "                # of features by pyradiomics\n",
    "                filename = os.path.join(external_drive_path, f\"{nodule_id}_cmask.npy\")\n",
    "                np.save(filename, cmask)\n",
    "                \n",
    "                volume = anns[0].scan.to_volume()\n",
    "                filename = os.path.join(external_drive_path, f\"{nodule_id}_volume.npy\")\n",
    "                np.save(filename, volume)\n",
    "                \n",
    "                # Extract the values of the features from xml\n",
    "                feature_values = {\n",
    "                    'Nodule_id': nodule_id,\n",
    "                    'Patient_id': patient_id,\n",
    "                    'Subtlety': nodule_characteristics[0][0],\n",
    "                    'Internalstructure': nodule_characteristics[0][1],\n",
    "                    'Calcification': nodule_characteristics[0][2],\n",
    "                    'Sphericity': nodule_characteristics[0][3],\n",
    "                    'Margin': nodule_characteristics[0][4],\n",
    "                    'Lobulation': nodule_characteristics[0][5],\n",
    "                    'Spiculation': nodule_characteristics[0][6],\n",
    "                    'Texture': nodule_characteristics[0][7],\n",
    "                    'Malignancy': malignancy_names.get(nodule_characteristics[0][8])\n",
    "                }\n",
    "\n",
    "                # Append the feature values to the nodule_data dictionary\n",
    "                for key, value in feature_values.items():\n",
    "                    nodule_data[key].append(value)\n",
    "                    \n",
    "features = pd.DataFrame(nodule_data)\n",
    "csv_filename = os.path.join(external_drive_path, 'features_pylidc_0.5.csv')\n",
    "features.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a8655",
   "metadata": {},
   "source": [
    "#### std_limit = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path were the images are stored\n",
    "input_directory = \"/home/cmonteiro/Aulas/Laboratório de IA e CD/Projeto 1/Imagens/LIDC-IDRI\"\n",
    "\n",
    "# Path to the setup file from radiomics\n",
    "params_file = \"/home/cmonteiro/pyradiomics-master/pyradiomics-master/examples/exampleSettings/Params.yaml\"\n",
    "\n",
    "external_drive_path = \"/mnt/d/Projeto 1/std_limit_1.0/\"\n",
    "\n",
    "# Ordered list of all the subfolders\n",
    "patient_folders = sorted(os.listdir(input_directory))\n",
    "nodule_id=0\n",
    "\n",
    "# Dictionary with all the correspondancies\n",
    "nodule_data = {\n",
    "    'Nodule_id': [],\n",
    "    'Patient_id': [],\n",
    "    'Subtlety': [],\n",
    "    'Internalstructure': [],\n",
    "    'Calcification': [],\n",
    "    'Sphericity': [],\n",
    "    'Margin': [],\n",
    "    'Lobulation': [],\n",
    "    'Spiculation': [],\n",
    "    'Texture': [],\n",
    "    'Malignancy': []\n",
    "}\n",
    "\n",
    "malignancy_names = {\n",
    "    1: \"1-Highly Unlikely\",\n",
    "    2: \"2-Moderately Unlikely\",\n",
    "    3: \"3-Indeterminate\",\n",
    "    4: \"4-Moderately Suspicious\",\n",
    "    5: \"5-Highly Suspicious\"\n",
    "}\n",
    "\n",
    "std_limit = 1.0\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    patient_folder_path = os.path.join(input_directory, patient_folder)\n",
    "    \n",
    "    # Id of the patient - 'LIDC-IDRI-xxxx'\n",
    "    patient_id = os.path.basename(patient_folder_path)\n",
    "    print(patient_id)\n",
    "    patient_scans = pl.query(pl.Scan).filter(pl.Scan.patient_id == patient_id, pl.Scan.annotations.any()).all()\n",
    "    \n",
    "    for scan in patient_scans:\n",
    "        nods = scan.cluster_annotations()\n",
    "        \n",
    "        # Iteration for each node\n",
    "        for anns in nods:\n",
    "            nodule_id+=1\n",
    "            \n",
    "            nodule_characteristics = []\n",
    "\n",
    "            # 50% consensus\n",
    "            cmask, cbbox, masks = consensus(anns, clevel=0.5, pad=[(20, 20), (20, 20), (0, 0)])\n",
    "\n",
    "            for i, mask in enumerate(masks):\n",
    "                characteristics = anns[i].feature_vals()\n",
    "                nodule_characteristics.append(characteristics)\n",
    "\n",
    "            # If there was some feature extracted, otherwise the nodule will not be included\n",
    "            if nodule_characteristics:\n",
    "                # Calculation of the stdeviation for each feature\n",
    "                std_deviations = [np.std(characteristic) for characteristic in zip(*nodule_characteristics)]\n",
    "        \n",
    "                # Verify if there is some feature which has a std > std_limit\n",
    "                if any(std > std_limit for std in std_deviations):\n",
    "                    # Ignore this nodule if its std is bigger\n",
    "                    print(f\"Nodule ID {nodule_id}\")\n",
    "\n",
    "                    continue\n",
    "                    \n",
    "                # If the nodule passes the condition: save its cmask and its volume so that it can be used on the extraction \n",
    "                # of features by pyradiomics\n",
    "                filename = os.path.join(external_drive_path, f\"{nodule_id}_cmask.npy\")\n",
    "                np.save(filename, cmask)\n",
    "                \n",
    "                volume = anns[0].scan.to_volume()\n",
    "                filename = os.path.join(external_drive_path, f\"{nodule_id}_volume.npy\")\n",
    "                np.save(filename, volume)\n",
    "                \n",
    "                # Extract the values of the features from xml\n",
    "                feature_values = {\n",
    "                    'Nodule_id': nodule_id,\n",
    "                    'Patient_id': patient_id,\n",
    "                    'Subtlety': nodule_characteristics[0][0],\n",
    "                    'Internalstructure': nodule_characteristics[0][1],\n",
    "                    'Calcification': nodule_characteristics[0][2],\n",
    "                    'Sphericity': nodule_characteristics[0][3],\n",
    "                    'Margin': nodule_characteristics[0][4],\n",
    "                    'Lobulation': nodule_characteristics[0][5],\n",
    "                    'Spiculation': nodule_characteristics[0][6],\n",
    "                    'Texture': nodule_characteristics[0][7],\n",
    "                    'Malignancy': malignancy_names.get(nodule_characteristics[0][8])\n",
    "                }\n",
    "\n",
    "                # Append the feature values to the nodule_data dictionary\n",
    "                for key, value in feature_values.items():\n",
    "                    nodule_data[key].append(value)\n",
    "                    \n",
    "features = pd.DataFrame(nodule_data)\n",
    "csv_filename = os.path.join(external_drive_path, 'features_pylidc_1.0.csv')\n",
    "features.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c68c1",
   "metadata": {},
   "source": [
    "#### std_limit = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path were the images are stored\n",
    "input_directory = \"/home/cmonteiro/Aulas/Laboratório de IA e CD/Projeto 1/Imagens/LIDC-IDRI\"\n",
    "\n",
    "# Path to the setup file from radiomics\n",
    "params_file = \"/home/cmonteiro/pyradiomics-master/pyradiomics-master/examples/exampleSettings/Params.yaml\"\n",
    "\n",
    "external_drive_path = \"/mnt/d/Projeto 1/std_limit_1.5/\"\n",
    "\n",
    "# Ordered list of all the subfolders\n",
    "patient_folders = sorted(os.listdir(input_directory))\n",
    "nodule_id=0\n",
    "\n",
    "# Dictionary with all the correspondancies\n",
    "nodule_data = {\n",
    "    'Nodule_id': [],\n",
    "    'Patient_id': [],\n",
    "    'Subtlety': [],\n",
    "    'Internalstructure': [],\n",
    "    'Calcification': [],\n",
    "    'Sphericity': [],\n",
    "    'Margin': [],\n",
    "    'Lobulation': [],\n",
    "    'Spiculation': [],\n",
    "    'Texture': [],\n",
    "    'Malignancy': []\n",
    "}\n",
    "\n",
    "malignancy_names = {\n",
    "    1: \"1-Highly Unlikely\",\n",
    "    2: \"2-Moderately Unlikely\",\n",
    "    3: \"3-Indeterminate\",\n",
    "    4: \"4-Moderately Suspicious\",\n",
    "    5: \"5-Highly Suspicious\"\n",
    "}\n",
    "\n",
    "std_limit = 1.5\n",
    "\n",
    "for patient_folder in patient_folders:\n",
    "    patient_folder_path = os.path.join(input_directory, patient_folder)\n",
    "    \n",
    "    # Id of the patient - 'LIDC-IDRI-xxxx'\n",
    "    patient_id = os.path.basename(patient_folder_path)\n",
    "    print(patient_id)\n",
    "    patient_scans = pl.query(pl.Scan).filter(pl.Scan.patient_id == patient_id, pl.Scan.annotations.any()).all()\n",
    "    \n",
    "    for scan in patient_scans:\n",
    "        nods = scan.cluster_annotations()\n",
    "        \n",
    "        # Iteration for each node\n",
    "        for anns in nods:\n",
    "            nodule_id+=1\n",
    "            \n",
    "            nodule_characteristics = []\n",
    "\n",
    "            # 50% consensus\n",
    "            cmask, cbbox, masks = consensus(anns, clevel=0.5, pad=[(20, 20), (20, 20), (0, 0)])\n",
    "\n",
    "            for i, mask in enumerate(masks):\n",
    "                characteristics = anns[i].feature_vals()\n",
    "                nodule_characteristics.append(characteristics)\n",
    "\n",
    "            # If there was some feature extracted, otherwise the nodule will not be included\n",
    "            if nodule_characteristics:\n",
    "                # Calculation of the stdeviation for each feature\n",
    "                std_deviations = [np.std(characteristic) for characteristic in zip(*nodule_characteristics)]\n",
    "        \n",
    "                # Verify if there is some feature which has a std > std_limit\n",
    "                if any(std > std_limit for std in std_deviations):\n",
    "                    # Ignore this nodule if its std is bigger\n",
    "                    print(f\"Nodule ID {nodule_id}\")\n",
    "\n",
    "                    continue\n",
    "                    \n",
    "                # If the nodule passes the condition: save its cmask and its volume so that it can be used on the extraction \n",
    "                # of features by pyradiomics\n",
    "                filename = os.path.join(external_drive_path, f\"{nodule_id}_cmask.npy\")\n",
    "                np.save(filename, cmask)\n",
    "                \n",
    "                volume = anns[0].scan.to_volume()\n",
    "                filename = os.path.join(external_drive_path, f\"{nodule_id}_volume.npy\")\n",
    "                np.save(filename, volume)\n",
    "                \n",
    "                # Extract the values of the features from xml\n",
    "                feature_values = {\n",
    "                    'Nodule_id': nodule_id,\n",
    "                    'Patient_id': patient_id,\n",
    "                    'Subtlety': nodule_characteristics[0][0],\n",
    "                    'Internalstructure': nodule_characteristics[0][1],\n",
    "                    'Calcification': nodule_characteristics[0][2],\n",
    "                    'Sphericity': nodule_characteristics[0][3],\n",
    "                    'Margin': nodule_characteristics[0][4],\n",
    "                    'Lobulation': nodule_characteristics[0][5],\n",
    "                    'Spiculation': nodule_characteristics[0][6],\n",
    "                    'Texture': nodule_characteristics[0][7],\n",
    "                    'Malignancy': malignancy_names.get(nodule_characteristics[0][8])\n",
    "                }\n",
    "\n",
    "                # Append the feature values to the nodule_data dictionary\n",
    "                for key, value in feature_values.items():\n",
    "                    nodule_data[key].append(value)\n",
    "                    \n",
    "features = pd.DataFrame(nodule_data)\n",
    "csv_filename = os.path.join(external_drive_path, 'features_pylidc_1.5.csv')\n",
    "features.to_csv(csv_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
