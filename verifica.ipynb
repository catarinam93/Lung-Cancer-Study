{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check IDs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verif_format_ids(data, data_id_column):\n",
    "    # Define the expected format pattern\n",
    "    expected_format_pattern = r'^LIDC-IDRI-\\d{4}$'\n",
    "\n",
    "    # Initialize a list to store IDs that don't match the format\n",
    "    different_format_ids = []\n",
    "\n",
    "    # Check each ID in the column, converting to strings as needed\n",
    "    for id_value in data[data_id_column]:\n",
    "        id_str = str(id_value)\n",
    "        if not re.match(expected_format_pattern, id_str):\n",
    "            different_format_ids.append(id_value)\n",
    "\n",
    "    if not different_format_ids:\n",
    "        print(f\"The format of IDs in column '{data_id_column}' is the same (LIDC-IDRI- followed by a four-digit number).\")\n",
    "    else:\n",
    "        print(f\"The format of IDs in column '{data_id_column}' is not the same.\")\n",
    "        print(\"IDs with different formats:\")\n",
    "        for id_value in different_format_ids:\n",
    "            print(id_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicated IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicated(data, data_id_column):\n",
    "    # Find duplicated IDs\n",
    "    duplicated_ids = data[data_id_column][data[data_id_column].duplicated(keep=False)]\n",
    "\n",
    "    # Print duplicate IDs (or not)\n",
    "    if not duplicated_ids.empty:\n",
    "        print(\"Duplicated IDs in column '\" + data_id_column + \"':\")\n",
    "        #diz qual o valor duplicado\n",
    "        print(duplicated_ids.unique())\n",
    "    else:\n",
    "        print(\"No duplicated IDs found in column '\" + data_id_column + \"'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if doesn't exist diferent ids between two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_different_ids(data1, data2, column1, column2):\n",
    "    # Get unique IDs from both columns\n",
    "    unique_ids1 = set(data1[column1].unique())\n",
    "    unique_ids2 = set(data2[column2].unique())\n",
    "    \n",
    "    # Check for differences\n",
    "    different_ids = unique_ids1.symmetric_difference(unique_ids2)\n",
    "    \n",
    "    return len(different_ids) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if there are still IDs with white spaces after removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_with_whitespace(data, data_id_column):\n",
    "    # Check for IDs with whitespace in df_metadata\n",
    "    ids_with_whitespace_data = data[data[data_id_column].str.contains(' ')]\n",
    "\n",
    "    # Print IDs with whitespace, if any\n",
    "    if not ids_with_whitespace_data.empty:\n",
    "        print(\"IDs with whitespace in :\")\n",
    "        print(ids_with_whitespace_data)\n",
    "    else:\n",
    "        print(\"No IDs with whitespace\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(data):\n",
    "    # Check missing values in all columns\n",
    "    missing = data.isna().sum()\n",
    "    \n",
    "    # Filter columns with missing values\n",
    "    columns_with_missing_data = missing[missing > 0]\n",
    "    \n",
    "    # Print columns with missing data and their counts\n",
    "    for column, count in columns_with_missing_data.items():\n",
    "        print(f\"Missing values in {column}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_values(dataframe):\n",
    "    # Create an empty dictionary to store the results\n",
    "    missing_values_dict = {}\n",
    "    \n",
    "    # Iterate over columns\n",
    "    for column in dataframe.columns:\n",
    "        # Get rows with missing values in the current column\n",
    "        missing_rows = dataframe.index[dataframe[column].isna()].tolist()\n",
    "        \n",
    "        # If there are missing rows in the column, store them in the dictionary\n",
    "        if missing_rows:\n",
    "            missing_values_dict[column] = missing_rows\n",
    "      \n",
    "    if not missing_values_dict:\n",
    "        print(\"No missing values found in the DataFrame.\")\n",
    "    \n",
    "    return missing_values_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(data):\n",
    "\n",
    "    null_count = data.isnull().sum().sum()  # Get the total count of null values\n",
    "    has_null_values = null_count > 0  # Check if there are null values\n",
    "\n",
    "    return has_null_values, null_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check for common IDs after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_common_ids(dataset1, column_id_dataset1, dataset2, column_id_dataset2):\n",
    "    unique_subject_ids_metadata = dataset1[column_id_dataset1].unique()\n",
    "    unique_tcia_ids_nodule = dataset2[column_id_dataset2].unique()\n",
    "\n",
    "    common_ids = set(unique_subject_ids_metadata) & set(unique_tcia_ids_nodule)\n",
    "\n",
    "    if len(common_ids) == 0:\n",
    "        print(\"No common IDs found between the two datasets.\")\n",
    "    else:\n",
    "        print(\"Common IDs found between the two datasets:\")\n",
    "        print(common_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for differences in IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_ids(dataset1, column_id_dataset1, dataset2, column_id_dataset2):\n",
    "    subject_ids_metadata = set(dataset1[column_id_dataset1])\n",
    "    tcia_ids_nodule = set(dataset2[column_id_dataset2])\n",
    "\n",
    "    if subject_ids_metadata == tcia_ids_nodule:\n",
    "        print(\"All IDs in both datasets match.\")\n",
    "    else:\n",
    "        print(\"IDs in the datasets do not match.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicate_columns(data):\n",
    "    duplicate_columns = set()\n",
    "    \n",
    "    # Iterate through each pair of columns and check if they have the same values\n",
    "    for i in range(len(data.columns)):\n",
    "        col1 = data.iloc[:, i]\n",
    "        for j in range(i + 1, len(data.columns)):\n",
    "            col2 = data.iloc[:, j]\n",
    "            if col1.equals(col2):\n",
    "                duplicate_columns.add(data.columns[i])\n",
    "                duplicate_columns.add(data.columns[j])\n",
    "    \n",
    "    return list(duplicate_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDs Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_ids(dataset1, column_id_dataset1, dataset2, column_id_dataset2):\n",
    "    unique_subject_ids_metadata = set(dataset1[column_id_dataset1])\n",
    "    unique_tcia_ids_nodule = set(dataset2[column_id_dataset2])\n",
    "\n",
    "    ids_only_in_metadata = unique_subject_ids_metadata - unique_tcia_ids_nodule\n",
    "    ids_only_in_nodule = unique_tcia_ids_nodule - unique_subject_ids_metadata\n",
    "\n",
    "    print(\"IDs only in metadata:\", ids_only_in_metadata)\n",
    "    print(\"IDs only in nodule:\", ids_only_in_nodule)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove WhiteSpaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_whiteSpace(data, data_id_column):\n",
    "    data[data_id_column] = data[data_id_column].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover valores ausentes\n",
    "def remove_missing_data(data, data_column):\n",
    "    data.dropna(subset=[data_column], inplace=True)\n",
    "\n",
    "# Preencher valores ausentes na coluna com uma string vazia\n",
    "def fill_missing_data(data, data_id_column):\n",
    "    data[data_id_column].fillna('', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude Unknown rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_unknown_rows(data, data_column, value_to_remove=0):\n",
    "    data = data[data[data_column] != value_to_remove]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process duplicated data using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_duplicated(data, data_id_column):\n",
    "    data.drop_duplicates(subset=data_id_column, keep='first', inplace=True)\n",
    "    data = data.groupby(data_id_column).mean(numeric_only=True).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get common ids_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_ids(dataset1, column_id_dataset1, dataset2, column_id_dataset2):\n",
    "    unique_subject_ids_metadata = dataset1[column_id_dataset1].unique()\n",
    "    unique_tcia_ids_nodule = dataset2[column_id_dataset2].unique()\n",
    "\n",
    "    common_ids = list(set(unique_subject_ids_metadata) & set(unique_tcia_ids_nodule))\n",
    "\n",
    "    return common_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the id format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(data, data_column_id, prefix):\n",
    "    data[data_column_id] = data[data_column_id].str.replace(prefix, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_null_values(data):\n",
    "    data_cleaned = data.dropna()\n",
    "    return data_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Nan with Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_with_zero(df):\n",
    "    return df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Columns with dtype string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_columns(dataframe):\n",
    "    string_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "    return string_columns\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
