{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import knn as knn   \n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "from numpy import array\n",
    "from numpy.linalg import norm\n",
    "from matplotlib.colors import ListedColormap\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, \\\n",
    " cross_val_score, GridSearchCV, RandomizedSearchCV,cross_validate,LeaveOneOut\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, mean_absolute_error,\\\n",
    "mean_squared_error, r2_score, f1_score,ConfusionMatrixDisplay,roc_curve,roc_auc_score, auc\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run All_Data_Together.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Default Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn \n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_(X_train, y_train, k, X_test, distance):\n",
    "    # Treinar o modelo k-NN\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k, metric=distance)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "   # test: novos dados para prever\n",
    "    predictions = knn_classifier.predict(X_test)\n",
    "    print(predictions)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = main.iloc[:, 1:].columns\n",
    "X = main[selected_columns].values\n",
    "y = df['maligancy'].values  #meter a malignancy aqui do que se retirou das anotações\n",
    "X_train, X_test, y_train = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "knn(X_train, y_train, 3, X_test, 'euclidean') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Bagging, using several distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.spatial.distance import chebyshev, minkowski, wminkowski, seuclidean, mahalanobis\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "class KNN_Bagging:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X, distance='euclidean'):\n",
    "        if distance == 'euclidean':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='euclidean')\n",
    "        elif distance == 'manhattan':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='manhattan')\n",
    "        elif distance == 'chebyshev':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='chebyshev')\n",
    "        elif distance == 'minkowski':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='minkowski')\n",
    "        elif distance == 'wminkowski':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='wminkowski')\n",
    "        elif distance == 'seuclidean':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='seuclidean')\n",
    "        elif distance == 'mahalanobis':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='mahalanobis', metric_params={'V': np.cov(self.X_train, rowvar=False)})\n",
    "        elif distance == 'hamming':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='hamming')\n",
    "        elif distance == 'canberra':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='canberra')\n",
    "        elif distance == 'braycurtis':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='braycurtis')\n",
    "        elif distance == 'jensenshannon':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='jensenshannon')\n",
    "        elif distance == 'yule':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='yule')\n",
    "        elif distance == 'matching':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='matching')\n",
    "        elif distance == 'dice':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='dice')\n",
    "        knn_classifier.fit(self.X_train, self.y_train)\n",
    "        predictions = knn_classifier.predict(X)\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X, distance='euclidean'):\n",
    "        if distance == 'euclidean':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='euclidean')\n",
    "        elif distance == 'manhattan':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='manhattan')\n",
    "        elif distance == 'chebyshev':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='chebyshev')\n",
    "        elif distance == 'minkowski':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='minkowski')\n",
    "        elif distance == 'wminkowski':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='wminkowsk'i)\n",
    "        elif distance == 'seuclidean':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='seuclidean')\n",
    "        elif distance == 'mahalanobis':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='mahalanobis', metric_params={'V': np.cov(self.X_train, rowvar=False)})\n",
    "        elif distance == 'hamming': \n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='hamming')\n",
    "        elif distance == 'canberra':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='canberra')\n",
    "        elif distance == 'braycurtis':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='braycurtis')\n",
    "        elif distance == 'jensenshannon':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='jensenshannon')\n",
    "        elif distance == 'yule':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='yule')\n",
    "        elif distance == 'matching':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='matching')\n",
    "        elif distance == 'dice':\n",
    "            knn_classifier = KNeighborsClassifier(n_neighbors=self.k, metric='dice')\n",
    "        knn_classifier.fit(self.X_train, self.y_train)\n",
    "        y_proba = knn_classifier.predict_proba(X)\n",
    "        return y_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "knn_bagging = KNN_Bagging(k)\n",
    "knn_bagging.fit(X_train, y_train)\n",
    "predictions_euclidean = knn_bagging.predict(X_test, distance='euclidean')\n",
    "predictions_manhattan = knn_bagging.predict(X_test, distance='manhattan')\n",
    "predictions_chebyshev = knn_bagging.predict(X_test, distance='chebyshev')\n",
    "predictions_wminkowski = knn_bagging.predict(X_test, distance='wminkowski')\n",
    "predictions_seuclidean = knn_bagging.predict(X_test, distance='seuclidean')\n",
    "predictions_mahalanobis = knn_bagging.predict(X_test, distance='mahalanobis')\n",
    "predictions_hamming = knn_bagging.predict(X_test, distance='hamming')\n",
    "predictions_canberra = knn_bagging.predict(X_test, distance='canberra')\n",
    "predictions_braycurtis = knn_bagging.predict(X_test, distance='braycurtis')\n",
    "predictions_jensenshannon = knn_bagging.predict(X_test, distance='jensenshannon')\n",
    "predictions_yule = knn_bagging.predict(X_test, distance='yule')\n",
    "predictions_matching = knn_bagging.predict(X_test, distance='matching')\n",
    "predictions_dice = knn_bagging.predict(X_test, distance='dice')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN: Different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_Features:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        predictions = list()\n",
    "        distances = [euclidean_distance_features(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train.reset_index(drop=True)[i] for i in k_indices]\n",
    "        k_nearest_labels = list(self.y_train.reset_index(drop=True).iloc[k_indices.ravel()])\n",
    "        unique_classes,counts=np.unique(k_nearest_labels, return_counts=True)\n",
    "        most_frequent_label=unique_classes[np.argmax(counts)]\n",
    "        most_common_str = str(most_frequent_label)\n",
    "        predictions.append(most_common_str)\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_proba = []\n",
    "        for sample in X:\n",
    "            distances = np.sqrt(np.sum(((self.X_train - sample)) ** 2, axis=1))\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            k_indices = sorted_indices[:self.k]\n",
    "            k_nearest_classes = self.y_train[k_indices]\n",
    "            unique_classes, counts = np.unique(k_nearest_classes, return_counts=True)\n",
    "            class_frequencies = counts / self.k  # relative frequency of the classes\n",
    "            y_proba.append(class_frequencies)\n",
    "        return np.array(y_proba)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
